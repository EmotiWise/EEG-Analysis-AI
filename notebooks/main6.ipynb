{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticket 6: Desarrollo de una Red Neuronal Básica\n",
    "\n",
    "En este notebook se construye y entrena una red neuronal simple (MLP) utilizando PyTorch, con el objetivo de clasificar estados de atención (alta vs baja) a partir de características extraídas de la señal EEG. La red toma como input las features calculadas (energía en bandas delta, theta, alpha y beta) y se entrena para predecir la etiqueta. Se evaluará el desempeño y se comparará con el modelo clásico previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('Librerías importadas correctamente.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos EEG cargados. Forma: (12258, 19)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo v1p.mat y asignar nombres de canales\n",
    "from scipy.io import loadmat\n",
    "\n",
    "mat_data = loadmat('v1p.mat', squeeze_me=True)\n",
    "data_array = mat_data['v1p']\n",
    "\n",
    "df = pd.DataFrame(data_array)\n",
    "channel_names = ['Fz', 'Cz', 'Pz', 'C3', 'T3', 'C4', 'T4', 'Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'T5', 'T6', 'O1', 'O2']\n",
    "if df.shape[1] == len(channel_names):\n",
    "    df.columns = channel_names\n",
    "else:\n",
    "    print('Advertencia: El número de columnas en el dataset no coincide con el número de canales esperados.')\n",
    "\n",
    "print('Datos EEG cargados. Forma:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de segmentos: 95\n",
      "Forma de la matriz de segmentos: (95, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna\\AppData\\Local\\Temp\\ipykernel_8300\\2925495082.py:29: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return np.trapz(Pxx[freq_idx], f[freq_idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 5 registros de features extraídos:\n",
      "           delta         theta        alpha         beta\n",
      "0   32459.691406  16640.219482  4972.186279  6119.483767\n",
      "1  245707.286133   9474.197876  3153.559708  4741.840615\n",
      "2    7549.710449   3950.868713   908.005569  1339.171967\n",
      "3    2155.812531   3338.061127  2545.681030  1929.724113\n",
      "4   25218.478149  14299.832520  2690.533386  1543.227493\n"
     ]
    }
   ],
   "source": [
    "# --- Segmentación y Extracción de Features ---\n",
    "\n",
    "# Parámetros de segmentación\n",
    "fs = 128  # Frecuencia de muestreo (Hz)\n",
    "segment_length = fs  # 1 segundo = 128 muestras\n",
    "num_samples = df.shape[0]\n",
    "num_segments = num_samples // segment_length\n",
    "print('Número de segmentos:', num_segments)\n",
    "\n",
    "# Extraer la señal del canal Fz\n",
    "signal = df['Fz'].values\n",
    "\n",
    "# Dividir la señal en segmentos\n",
    "segments = []\n",
    "for i in range(num_segments):\n",
    "    start = i * segment_length\n",
    "    end = start + segment_length\n",
    "    segments.append(signal[start:end])\n",
    "segments = np.array(segments)\n",
    "print('Forma de la matriz de segmentos:', segments.shape)\n",
    "\n",
    "# Función para calcular la potencia en una banda de frecuencia\n",
    "from scipy.signal import welch\n",
    "\n",
    "def bandpower(data, fs, band, nperseg=128):\n",
    "    \"\"\"Calcula la potencia de la señal en una banda específica usando Welch.\"\"\"\n",
    "    f, Pxx = welch(data, fs=fs, nperseg=nperseg)\n",
    "    freq_idx = (f >= band[0]) & (f <= band[1])\n",
    "    return np.trapz(Pxx[freq_idx], f[freq_idx])\n",
    "\n",
    "# Definir bandas de frecuencia\n",
    "bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30)\n",
    "}\n",
    "\n",
    "# Extraer features para cada segmento (energía en cada banda)\n",
    "features_list = []\n",
    "for seg in segments:\n",
    "    features = {}\n",
    "    for band_name, band_range in bands.items():\n",
    "        features[band_name] = bandpower(seg, fs, band_range, nperseg=segment_length)\n",
    "    features_list.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(features_list)\n",
    "print('Primeros 5 registros de features extraídos:')\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mediano de potencia en alpha: 2406.608139038086\n",
      "Tabla de features con etiquetas:\n",
      "           delta         theta        alpha         beta  Label Label_str\n",
      "0   32459.691406  16640.219482  4972.186279  6119.483767      1   Control\n",
      "1  245707.286133   9474.197876  3153.559708  4741.840615      1   Control\n",
      "2    7549.710449   3950.868713   908.005569  1339.171967      0      TDAH\n",
      "3    2155.812531   3338.061127  2545.681030  1929.724113      1   Control\n",
      "4   25218.478149  14299.832520  2690.533386  1543.227493      1   Control\n"
     ]
    }
   ],
   "source": [
    "# --- Asignación de Etiquetas Simuladas ---\n",
    "\n",
    "# Se simulan etiquetas basadas en la potencia en banda alpha\n",
    "median_alpha = features_df['alpha'].median()\n",
    "print('Valor mediano de potencia en alpha:', median_alpha)\n",
    "\n",
    "# Asignar etiqueta: 1 para alta atención (Control), 0 para baja atención (TDAH)\n",
    "features_df['Label'] = (features_df['alpha'] > median_alpha).astype(int)\n",
    "features_df['Label_str'] = features_df['Label'].map({1: 'Control', 0: 'TDAH'})\n",
    "\n",
    "print('Tabla de features con etiquetas:')\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño entrenamiento: (66, 4) | Tamaño prueba: (29, 4)\n"
     ]
    }
   ],
   "source": [
    "# --- Preparación de los Datos para PyTorch ---\n",
    "\n",
    "# Seleccionar features y etiquetas\n",
    "X = features_df[['delta', 'theta', 'alpha', 'beta']].values.astype(np.float32)\n",
    "y = features_df['Label'].values.astype(np.int64)\n",
    "\n",
    "# Dividir en entrenamiento y prueba (70% train, 30% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Tamaño entrenamiento:', X_train.shape, '| Tamaño prueba:', X_test.shape)\n",
    "\n",
    "# Convertir a tensores\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "# Crear DataLoader para batches\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquitectura del modelo:\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- Definición de la Arquitectura de la Red Neuronal (MLP) ---\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim1=16, hidden_dim2=8, output_dim=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = MLP()\n",
    "print('Arquitectura del modelo:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando la red neuronal...\n",
      "Epoch 1/50, Loss: 329.6317\n",
      "Epoch 2/50, Loss: 146.8162\n",
      "Epoch 3/50, Loss: 70.8063\n",
      "Epoch 4/50, Loss: 9.0916\n",
      "Epoch 5/50, Loss: 8.2279\n",
      "Epoch 6/50, Loss: 1.8707\n",
      "Epoch 7/50, Loss: 1.1260\n",
      "Epoch 8/50, Loss: 1.0364\n",
      "Epoch 9/50, Loss: 0.6134\n",
      "Epoch 10/50, Loss: 0.6794\n",
      "Epoch 11/50, Loss: 0.6794\n",
      "Epoch 12/50, Loss: 0.6764\n",
      "Epoch 13/50, Loss: 0.6372\n",
      "Epoch 14/50, Loss: 0.6319\n",
      "Epoch 15/50, Loss: 0.6244\n",
      "Epoch 16/50, Loss: 0.6212\n",
      "Epoch 17/50, Loss: 0.6202\n",
      "Epoch 18/50, Loss: 0.6196\n",
      "Epoch 19/50, Loss: 0.5688\n",
      "Epoch 20/50, Loss: 0.5968\n",
      "Epoch 21/50, Loss: 0.5957\n",
      "Epoch 22/50, Loss: 0.5562\n",
      "Epoch 23/50, Loss: 0.5696\n",
      "Epoch 24/50, Loss: 0.4900\n",
      "Epoch 25/50, Loss: 0.5352\n",
      "Epoch 26/50, Loss: 0.5761\n",
      "Epoch 27/50, Loss: 0.5747\n",
      "Epoch 28/50, Loss: 0.5257\n",
      "Epoch 29/50, Loss: 0.6033\n",
      "Epoch 30/50, Loss: 0.5708\n",
      "Epoch 31/50, Loss: 0.5699\n",
      "Epoch 32/50, Loss: 0.6041\n",
      "Epoch 33/50, Loss: 0.6046\n",
      "Epoch 34/50, Loss: 0.5691\n",
      "Epoch 35/50, Loss: 0.6409\n",
      "Epoch 36/50, Loss: 0.6040\n",
      "Epoch 37/50, Loss: 0.6035\n",
      "Epoch 38/50, Loss: 0.6033\n",
      "Epoch 39/50, Loss: 0.6024\n",
      "Epoch 40/50, Loss: 0.6021\n",
      "Epoch 41/50, Loss: 0.6019\n",
      "Epoch 42/50, Loss: 0.6017\n",
      "Epoch 43/50, Loss: 0.5758\n",
      "Epoch 44/50, Loss: 0.6284\n",
      "Epoch 45/50, Loss: 0.5525\n",
      "Epoch 46/50, Loss: 0.5515\n",
      "Epoch 47/50, Loss: 0.5789\n",
      "Epoch 48/50, Loss: 0.5508\n",
      "Epoch 49/50, Loss: 0.6011\n",
      "Epoch 50/50, Loss: 0.6010\n",
      "\n",
      "Evaluando el modelo en datos de prueba...\n",
      "Precisión en test: 0.5517241379310345\n",
      "Matriz de confusión:\n",
      "[[13  0]\n",
      " [13  3]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        13\n",
      "           1       1.00      0.19      0.32        16\n",
      "\n",
      "    accuracy                           0.55        29\n",
      "   macro avg       0.75      0.59      0.49        29\n",
      "weighted avg       0.78      0.55      0.47        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Definir Función de Costo, Optimizador y Ciclo de Entrenamiento ---\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    print(\"Precisión en test:\", acc)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(confusion_matrix(all_targets, all_preds))\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(all_targets, all_preds))\n",
    "\n",
    "print('Entrenando la red neuronal...')\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50)\n",
    "\n",
    "print('\\nEvaluando el modelo en datos de prueba...')\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones e Interpretación\n",
    "\n",
    "El modelo de red neuronal MLP fue entrenado utilizando las características extraídas de segmentos de EEG (potencia en bandas delta, theta, alpha y beta). Se entrenó y evaluó en un conjunto de datos simulados para clasificar estados de atención (alta vs baja). La precisión, la matriz de confusión y el reporte de clasificación permiten valorar el desempeño del modelo. Además, el análisis de los coeficientes (o la importancia de cada feature) puede sugerir qué bandas de frecuencia son más relevantes para distinguir los estados mentales.\n",
    "\n",
    "**Consejo Profesional:**\n",
    "\n",
    "El desarrollo de una red neuronal requiere una correcta estructuración de los datos, la selección adecuada de la arquitectura y el ajuste meticuloso de hiperparámetros. Experimenta con diferentes configuraciones, técnicas de regularización y estrategias de validación para mejorar la robustez y precisión del modelo. Una evaluación cuidadosa de las features y su relevancia es clave para avanzar en proyectos de inteligencia artificial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
